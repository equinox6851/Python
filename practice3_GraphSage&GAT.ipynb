{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **AAI0026 Practice 3: GraphSage and GAT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In Practice 2, we constructed GNN models by using PyTorch Geometric built in GCN layer, the `GCNConv`. In this Colab we will implement the **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) and **GAT** ([Veličković et al. (2018)](https://arxiv.org/abs/1710.10903)) layers directly. Then we will run our models on the CORA dataset, which is a standard citation network benchmark dataset.\n",
        "\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "# Device\n",
        "You might need to use GPU for this Colab.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "7e8a2833-e21a-44bc-f9b0-c68f8dd62380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 33.0 MB/s \n",
            "\u001b[?25h  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 467 kB 29.3 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PRfgbfTjCRD_",
        "outputId": "a1281aea-e649-4af8-c899-deb03f4763d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXlf4MtYrbz"
      },
      "source": [
        "# 1 GNN Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQy2RBfgYut4"
      },
      "source": [
        "## Implementing Layer Modules\n",
        "\n",
        "In colab 2, we implemented a network using GCN in node and graph classification tasks. However, the GCN module we used in colab 2 is from the official library. For this problem, we will provide you with a general Graph Neural Network Stack, where you'll be able to plugin your own modules of GraphSAGE and GATs. We will use our implementations to complete node classification on CORA, which is a standard citation network benchmark dataset. In this dataset, nodes correspond to documents and edges correspond to undirected citations. Each node has a class label. The node features are elements of a bag-or-words representation of a document. For the Cora dataset, there are 2708 nodes, 5429 edges, 7 prediction classes for nodes, and 1433 features per node. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4ne6Gw-CT5G"
      },
      "source": [
        "## GNN Stack Module\n",
        "\n",
        "Below is the implementation for a general GNN Module that could plugin any layers, including **GraphSage**, **GAT**, etc. This module is provided for you, and your own **GraphSage** and **GAT** layers will function as components in the GNNStack Module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ys8vZAFPCWWe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_scatter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Union, Tuple, Optional\n",
        "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
        "                                    OptTensor)\n",
        "\n",
        "from torch.nn import Parameter, Linear\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "# https://greeksharifa.github.io/pytorch/2021/09/04/MP/\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
        "\n",
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(args.model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "        self.emb = emb\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GraphSage':\n",
        "            return GraphSage\n",
        "        elif model_type == 'GAT':\n",
        "            # When applying GAT with num heads > 1, one needs to modify the \n",
        "            # input and output dimension of the conv layers (self.convs),\n",
        "            # to ensure that the input dim of the next layer is num heads\n",
        "            # multiplied by the output dim of the previous layer.\n",
        "            # HINT: In case you want to play with multiheads, you need to change the for-loop when builds up self.convs to be\n",
        "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
        "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "          \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout)\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        if self.emb == True:\n",
        "            return x\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syDtxjxoCZgq"
      },
      "source": [
        "## GraphSage Implementation\n",
        "\n",
        "Now let's start working on our own implementation of layers! This part is to get you familiar with how to implement Pytorch layer based on Message Passing. You will be implementing the **forward**, **message** and **aggregate** functions.\n",
        "\n",
        "Generally, the **forward** function is where the actual message passing is conducted. All logic in each iteration happens in **forward**, where we'll call **propagate** function to propagate information from neighbor nodes to central nodes.  So the general paradigm will be pre-processing -> propagate -> post-processing.\n",
        "\n",
        "Recall the process of message passing we introduced. **propagate** further calls **message** which transforms information of neighbor nodes into messages, **aggregate** which aggregates all messages from neighbor nodes into one, and **update** which further generates the embedding for nodes in the next iteration.\n",
        "\n",
        "Our implementation is slightly variant from this, where we'll not explicitly implement **update**, but put the logic for updating nodes in **forward** function. To be more specific, after information is propagated, we can further conduct some operations on the output of **propagate**. The output of **forward** is exactly the embeddings after the current iteration.\n",
        "\n",
        "In addition, tensors passed to **propagate()** can be mapped to the respective nodes $i$ and $j$ by appending _i or _j to the variable name, .e.g. x_i and x_j. Note that we generally refer to $i$ as the central nodes that aggregates information, and refer to $j$ as the neighboring nodes, since this is the most common notation.\n",
        "\n",
        "Please find more details in the comments. One thing to note is that we're adding **skip connections** to our GraphSage. Formally, the update rule for our model is described as below:\n",
        "\n",
        "\\begin{equation}\n",
        "h_v^{(l)} = W_l\\cdot h_v^{(l-1)} + W_r \\cdot AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\})\n",
        "\\end{equation}\n",
        "\n",
        "For simplicity, we use mean aggregations where:\n",
        "\n",
        "\\begin{equation}\n",
        "AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\}) = \\frac{1}{|N(v)|} \\sum_{u\\in N(v)} h_u^{(l-1)}\n",
        "\\end{equation}\n",
        "\n",
        "Additionally, $\\ell$-2 normalization is applied after each iteration.\n",
        "\n",
        "In order to complete the work correctly, we have to understand how the different functions interact with each other. In **propagate** we can pass in any parameters we want. For example, we pass in $x$ as an parameter:\n",
        "\n",
        "... = propagate(..., $x$=($x_{central}$, $x_{neighbor}$), ...)\n",
        "\n",
        "Here $x_{central}$ and $x_{neighbor}$ represent the features from **central** nodes and from **neighbor** nodes. If we're using the same representations from central and neighbor, then $x_{central}$ and $x_{neighbor}$ could be identical.\n",
        "\n",
        "Suppose $x_{central}$ and $x_{neighbor}$ are both of shape N * d, where N is number of nodes, and d is dimension of features.\n",
        "\n",
        "Then in message function, we can take parameters called $x\\_i$ and $x\\_j$. Usually $x\\_i$ represents \"central nodes\", and $x\\_j$ represents \"neighbor nodes\". Pay attention to the shape here: $x\\_i$ and $x\\_j$ are both of shape E * d (**not N!**). $x\\_i$ is obtained by concatenating the embeddings of central nodes of all edges through lookups from $x_{central}$ we passed in propagate. Similarly, $x\\_j$ is obtained by concatenating the embeddings of neighbor nodes of all edges through lookups from $x_{neighbor}$ we passed in propagate.\n",
        "\n",
        "Let's look at an example. Suppose we have 4 nodes, so $x_{central}$ and $x_{neighbor}$ are of shape 4 * d. We have two edges (1, 2) and (3, 0). Thus, $x\\_i$ is obtained by $[x_{central}[1]^T; x_{central}[3]^T]^T$, and $x\\_j$ is obtained by $[x_{neighbor}[2]^T; x_{neighbor}[0]^T]^T$\n",
        "\n",
        "<font color='red'>For the following questions, DON'T refer to any existing implementations online.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RwG4HqCFCaOD"
      },
      "outputs": [],
      "source": [
        "class GraphSage(MessagePassing):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, normalize = True,\n",
        "                 bias = False, **kwargs):  \n",
        "        super(GraphSage, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalize = normalize\n",
        "\n",
        "        self.lin_l = None\n",
        "        self.lin_r = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the layers needed for the message and update functions below.\n",
        "        # self.lin_l is the linear transformation that you apply to embedding \n",
        "        #            for central node.\n",
        "        # self.lin_r is the linear transformation that you apply to aggregated \n",
        "        #            message from neighbors.\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        self.lin_l = torch.nn.Linear(self.in_channels, self.out_channels)\n",
        "        self.lin_r = torch.nn.Linear(self.in_channels, self.out_channels)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_l.reset_parameters()\n",
        "        self.lin_r.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        \"\"\"\"\"\"\n",
        "\n",
        "        out = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement message passing, as well as any post-processing (our update rule).\n",
        "        # 1. First call propagate function to conduct the message passing.\n",
        "        #    1.1 See there for more information: \n",
        "        #        https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        #    1.2 We use the same representations for central (x_central) and \n",
        "        #        neighbor (x_neighbor) nodes, which means you'll pass x=(x, x) \n",
        "        #        to propagate.\n",
        "        # 2. Update our node embedding with skip connection.\n",
        "        # 3. If normalize is set, do L-2 normalization (defined in \n",
        "        #    torch.nn.functional)\n",
        "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        out = self.propagate(edge_index, x=x, size=size)\n",
        "        out= self.lin_r(out)\n",
        "        x = self.lin_l(x)\n",
        "        dout = x + out\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "\n",
        "        out = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your message function here.\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "\n",
        "        out = None\n",
        "\n",
        "        # The axis along which to index number of nodes.\n",
        "        node_dim = self.node_dim\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter: \n",
        "        # https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        out = torch_scatter.scatter(inputs, index, self.node_dim,dim_size = dim_size, reduce = 'mean')\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qx1bA2m1SWA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjcfF3RACdLD"
      },
      "source": [
        "## GAT Implementation\n",
        "\n",
        "Attention mechanisms have become the state-of-the-art in many sequence-based tasks such as machine translation and learning sentence representations. One of the major benefits of attention-based mechanisms is their ability to focus on the most relevant parts of the input to make decisions. In this problem, we will see how attention mechanisms can be used to perform node classification of graph-structured data through the usage of Graph Attention Networks (GATs).\n",
        "\n",
        "The building block of the Graph Attention Network is the graph attention layer, which is a variant of the aggregation function . Let $N$ be the number of nodes and $F$ be the dimension of the feature vector for each node. The input to each graph attentional layer is a set of node features: $\\mathbf{h} = \\{\\overrightarrow{h_1}, \\overrightarrow{h_2}, \\dots, \\overrightarrow{h_N}$\\}, $\\overrightarrow{h_i} \\in R^F$. The output of each graph attentional layer is a new set of node features, which may have a new dimension $F'$: $\\mathbf{h'} = \\{\\overrightarrow{h_1'}, \\overrightarrow{h_2'}, \\dots, \\overrightarrow{h_N'}\\}$, with $\\overrightarrow{h_i'} \\in \\mathbb{R}^{F'}$.\n",
        "\n",
        "We will now describe this transformation of the input features into higher-level features performed by each graph attention layer. First, a shared linear transformation parametrized by the weight matrix $\\mathbf{W} \\in \\mathbb{R}^{F' \\times F}$ is applied to every node. Next, we perform self-attention on the nodes. We use a shared attentional mechanism:\n",
        "\\begin{equation} \n",
        "a : \\mathbb{R}^{F'} \\times \\mathbb{R}^{F'} \\rightarrow \\mathbb{R}.\n",
        "\\end{equation}\n",
        "\n",
        "This mechanism computes the attention coefficients that capture the importance of node $j$'s features to node $i$:\n",
        "\\begin{equation}\n",
        "e_{ij} = a(\\mathbf{W_l}\\overrightarrow{h_i}, \\mathbf{W_r} \\overrightarrow{h_j})\n",
        "\\end{equation}\n",
        "The most general formulation of self-attention allows every node to attend to all other nodes which drops all structural information. To utilize graph structure in the attention mechanisms, we can use masked attention. In masked attention, we only compute $e_{ij}$ for nodes $j \\in \\mathcal{N}_i$ where $\\mathcal{N}_i$ is some neighborhood of node $i$ in the graph.\n",
        "\n",
        "To easily compare coefficients across different nodes, we normalize the coefficients across $j$ using a softmax function:\n",
        "\\begin{equation}\n",
        "\\alpha_{ij} = \\text{softmax}_j(e_{ij}) = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}_i} \\exp(e_{ik})}\n",
        "\\end{equation}\n",
        "\n",
        "For this problem, our attention mechanism $a$ will be a single-layer feedforward neural network parametrized by a weight vector $\\overrightarrow{a} \\in \\mathbb{R}^{F'}$, followed by a LeakyReLU nonlinearity (with negative input slope 0.2). Let $\\cdot^T$ represent transposition and $||$ represent concatenation. The coefficients computed by our attention mechanism may be expressed as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\alpha_{ij} = \\frac{\\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_j}\\Big)\\Big)}{\\sum_{k\\in \\mathcal{N}_i} \\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_k}\\Big)\\Big)}\n",
        "\\end{equation}\n",
        "\n",
        "For the following questions, we denote $\\alpha_l = [...,\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i},...]$ and $\\alpha_r = [..., \\overrightarrow{a_r}^T \\mathbf{W_r} \\overrightarrow{h_j}, ...]$.\n",
        "\n",
        "\n",
        "At every layer of GAT, after the attention coefficients are computed for that layer, the aggregation function can be computed by a weighted sum of neighborhood messages, where weights are specified by $\\alpha_{ij}$.\n",
        "\n",
        "Now, we use the normalized attention coefficients to compute a linear combination of the features corresponding to them. These aggregated features will serve as the final output features for every node.\n",
        "\n",
        "\\begin{equation}\n",
        "h_i' = \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij} \\mathbf{W_r} \\overrightarrow{h_j}.\n",
        "\\end{equation}\n",
        "\n",
        "To stabilize the learning process of self-attention, we use multi-head attention. To do this we use $K$ independent attention mechanisms, or ``heads'' compute output features as in the above equations. Then, we concatenate these output feature representations:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\overrightarrow{h_i}' = ||_{k=1}^K \\Big(\\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}^{(k)} \\mathbf{W_r}^{(k)} \\overrightarrow{h_j}\\Big)\n",
        "\\end{equation}\n",
        "\n",
        "where $||$ is concentation, $\\alpha_{ij}^{(k)}$ are the normalized attention coefficients computed by the $k$-th attention mechanism $(a^k)$, and $\\mathbf{W}^{(k)}$ is the corresponding input linear transformation's weight matrix. Note that for this setting, $\\mathbf{h'} \\in \\mathbb{R}^{KF'}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w4j45gTpCeXO"
      },
      "outputs": [],
      "source": [
        "class GAT(MessagePassing):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, heads = 2,\n",
        "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
        "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = heads\n",
        "        self.negative_slope = negative_slope\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.lin_l = None\n",
        "        self.lin_r = None\n",
        "        self.att_l = None\n",
        "        self.att_r = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the layers needed for the message functions below.\n",
        "        # self.lin_l is the linear transformation that you apply to embeddings \n",
        "        # BEFORE message passing.\n",
        "        # Pay attention to dimensions of the linear layers, since we're using \n",
        "        # multi-head attention.\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        self.lin_l = torch.nn.Linear(in_channels, heads * out_channels)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        self.lin_r = self.lin_l\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the attention parameters \\overrightarrow{a_l/r}^T in the above intro.\n",
        "        # You have to deal with multi-head scenarios.\n",
        "        # Use nn.Parameter instead of nn.Linear\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        self.att_l = Parameter(torch.Tensor(1, self.heads, out_channels))\n",
        "        self.att_r = Parameter(torch.Tensor(1, self.heads, out_channels))\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
        "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
        "        nn.init.xavier_uniform_(self.att_l)\n",
        "        nn.init.xavier_uniform_(self.att_r)\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        \n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement message passing, as well as any pre- and post-processing (our update rule).\n",
        "        # 1. First apply linear transformation to node embeddings, and split that \n",
        "        #    into multiple heads. We use the same representations for source and\n",
        "        #    target nodes, but apply different linear weights (W_l and W_r)\n",
        "        # 2. Calculate alpha vectors for central nodes (alpha_l) and neighbor nodes (alpha_r).\n",
        "        # 3. Call propagate function to conduct the message passing. \n",
        "        #    3.1 Remember to pass alpha = (alpha_l, alpha_r) as a parameter.\n",
        "        #    3.2 See there for more information: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        # 4. Transform the output back to the shape of N * d.\n",
        "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        x_l = self.lin_l(x).reshape(-1, H, C)\n",
        "        x_r = self.lin_r(x).reshape(-1, H, C)\n",
        "        alpha_l = self.att_l * x_l\n",
        "        alpha_r = self.att_r * x_r\n",
        "        out = self.propagate(edge_index, x=(x_l, x_r), alpha=(alpha_l, alpha_r), size=size)\n",
        "        out = out.reshape(-1, H*C)\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your message function. Putting the attention in message \n",
        "        # instead of in update is a little tricky.\n",
        "        # 1. Calculate the final attention weights using alpha_i and alpha_j,\n",
        "        #    and apply leaky Relu.\n",
        "        # 2. Calculate softmax over the neighbor nodes for all the nodes. Use \n",
        "        #    torch_geometric.utils.softmax instead of the one in Pytorch.\n",
        "        # 3. Apply dropout to attention weights (alpha).\n",
        "        # 4. Multiply embeddings and attention weights. As a sanity check, the output\n",
        "        #    should be of shape E * H * d.\n",
        "        # 5. ptr (LongTensor, optional): If given, computes the softmax based on\n",
        "        #    sorted inputs in CSR representation. You can simply pass it to softmax.\n",
        "        # Don't worry if you deviate from this.\n",
        "\n",
        "        alpha = F.leaky_relu(alpha_i + alpha_j, negative_slope=self.negative_slope)\n",
        "        if ptr:\n",
        "            att_weight = F.softmax(alpha_i + alpha_j, ptr)\n",
        "        else:\n",
        "            att_weight = torch_geometric.utils.softmax(alpha, index)\n",
        "        # Fill below with 2 lines \n",
        "        alpha = F.dropout(alpha, p=self.dropout)\n",
        "        out = alpha.unsqueeze(-1)* x_j\n",
        "        \n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter: https://pytorch-scatter.readthedocs.io/en/latest/_modules/torch_scatter/scatter.html\n",
        "        # Pay attention to \"reduce\" parameter is different from that in GraphSage.\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        \n",
        "        out = torch_scatter.scatter(inputs, index, self.node_dim, dim_size=dim_size, reduce='sum')\n",
        "        ############################################################################\n",
        "    \n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2dkgSuWCheU"
      },
      "source": [
        "## Building Optimizers\n",
        "\n",
        "This function has been implemented for you. **For grading purposes please use the default Adam optimizer**, but feel free to play with other types of optimizers on your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f_TIQ8NPCjBP"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "    return scheduler, optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBYdWFwYCkwY"
      },
      "source": [
        "## Training and Testing\n",
        "\n",
        "Here we provide you with the functions to train and test. **Please do not modify this part for grading purposes.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_tZMWRc8CmGg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def train(dataset, args):\n",
        "    \n",
        "    print(\"Node task. test set size:\", np.sum(dataset[0]['train_mask'].numpy()))\n",
        "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
        "                            args)\n",
        "    scheduler, opt = build_optimizer(args, model.parameters())\n",
        "\n",
        "    # train\n",
        "    losses = []\n",
        "    test_accs = []\n",
        "    for epoch in range(args.epochs):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in loader:\n",
        "            opt.zero_grad()\n",
        "            pred = model(batch)\n",
        "            label = batch.y\n",
        "            pred = pred[batch.train_mask]\n",
        "            label = label[batch.train_mask]\n",
        "            loss = model.loss(pred, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "        total_loss /= len(loader.dataset)\n",
        "        losses.append(total_loss)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "          test_acc = test(test_loader, model)\n",
        "          test_accs.append(test_acc)\n",
        "          print(\"Epoch \", epoch, \"Loss: \", total_loss, \"Test Acc.: \", test_acc)\n",
        "        else:\n",
        "          test_accs.append(test_accs[-1])\n",
        "    return test_accs, losses\n",
        "\n",
        "def test(loader, model, is_validation=True):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        with torch.no_grad():\n",
        "            # max(dim=1) returns values, indices tuple; only need indices\n",
        "            pred = model(data).max(dim=1)[1]\n",
        "            label = data.y\n",
        "\n",
        "        mask = data.val_mask if is_validation else data.test_mask\n",
        "        # node classification: only evaluate on nodes in test set\n",
        "        pred = pred[mask]\n",
        "        label = data.y[mask]\n",
        "            \n",
        "        correct += pred.eq(label).sum().item()\n",
        "\n",
        "    total = 0\n",
        "    for data in loader.dataset:\n",
        "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
        "    return correct / total\n",
        "  \n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7-h7jIsCns4"
      },
      "source": [
        "## Let's Start the Training!\n",
        "\n",
        "We will be working on the CORA dataset on node-level classification.\n",
        "\n",
        "This part is implemented for you. **For grading purposes, please do not modify the default parameters.** However, feel free to play with different configurations just for fun!\n",
        "\n",
        "**Submit your best accuracy and loss on Gradescope.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "qe9B45l9Cpz2",
        "outputId": "f0dcabde-7ac2-4895-809a-d1a6c127c648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node task. test set size: 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e6e530c0b3dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-e6e530c0b3dc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mtest_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Maximum accuracy: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-b7a2e075c72f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, args)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-38948a84ff15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-b0ca14ebdd47>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Our implementation is ~5 lines, but don't worry if you deviate from this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                         \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-b0ca14ebdd47>\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, dim_size)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Our implementation is ~1 lines, but don't worry if you deviate from this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_scatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter_mean\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m                  \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                  dim_size: Optional[int] = None) -> torch.Tensor:\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mdim_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter_sum\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 dim_size: Optional[int] = None) -> torch.Tensor:\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_scatter/utils.py\u001b[0m in \u001b[0;36mbroadcast\u001b[0;34m(src, other, dim)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dim'"
          ]
        }
      ],
      "source": [
        "# GraphSage\n",
        "\n",
        "def main():\n",
        "    for args in [\n",
        "        {'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
        "         'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 500, \n",
        "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, \n",
        "         'weight_decay': 5e-3, 'lr': 0.01},\n",
        "    ]:\n",
        "        args = objectview(args)\n",
        "        for model in ['GraphSage']:\n",
        "            args.model_type = model\n",
        "\n",
        "            # Match the dimension.\n",
        "            if model == 'GAT':\n",
        "              args.heads = 2\n",
        "            else:\n",
        "              args.heads = 1\n",
        "\n",
        "            if args.dataset == 'cora':\n",
        "                dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
        "            else:\n",
        "                raise NotImplementedError(\"Unknown dataset\") \n",
        "            test_accs, losses = train(dataset, args) \n",
        "\n",
        "            print(\"Maximum accuracy: {0}\".format(max(test_accs)))\n",
        "            print(\"Minimum loss: {0}\".format(min(losses)))\n",
        "\n",
        "            plt.title(dataset.name)\n",
        "            plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n",
        "            plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1bYmz-q93HLk",
        "outputId": "b6196ba1-ae8d-4537-a033-51854bc39d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node task. test set size: 140\n",
            "Epoch  0 Loss:  1.9566068649291992 Test Acc.:  0.104\n",
            "Epoch  10 Loss:  1.0250568389892578 Test Acc.:  0.486\n",
            "Epoch  20 Loss:  0.2713371515274048 Test Acc.:  0.674\n",
            "Epoch  30 Loss:  0.13003231585025787 Test Acc.:  0.722\n",
            "Epoch  40 Loss:  0.09789977967739105 Test Acc.:  0.712\n",
            "Epoch  50 Loss:  0.11593309044837952 Test Acc.:  0.678\n",
            "Epoch  60 Loss:  0.09242720901966095 Test Acc.:  0.666\n",
            "Epoch  70 Loss:  0.12858586013317108 Test Acc.:  0.722\n",
            "Epoch  80 Loss:  0.04588910937309265 Test Acc.:  0.726\n",
            "Epoch  90 Loss:  0.09208666533231735 Test Acc.:  0.718\n",
            "Epoch  100 Loss:  0.05639316514134407 Test Acc.:  0.726\n",
            "Epoch  110 Loss:  0.08017326891422272 Test Acc.:  0.71\n",
            "Epoch  120 Loss:  0.09598377346992493 Test Acc.:  0.732\n",
            "Epoch  130 Loss:  0.050167299807071686 Test Acc.:  0.704\n",
            "Epoch  140 Loss:  0.04777543619275093 Test Acc.:  0.734\n",
            "Epoch  150 Loss:  0.05792825669050217 Test Acc.:  0.72\n",
            "Epoch  160 Loss:  0.05302969738841057 Test Acc.:  0.728\n",
            "Epoch  170 Loss:  0.07059156149625778 Test Acc.:  0.716\n",
            "Epoch  180 Loss:  0.07883428782224655 Test Acc.:  0.69\n",
            "Epoch  190 Loss:  0.03828642889857292 Test Acc.:  0.722\n",
            "Epoch  200 Loss:  0.05661905184388161 Test Acc.:  0.708\n",
            "Epoch  210 Loss:  0.06892883777618408 Test Acc.:  0.734\n",
            "Epoch  220 Loss:  0.10103548318147659 Test Acc.:  0.744\n",
            "Epoch  230 Loss:  0.041787538677453995 Test Acc.:  0.724\n",
            "Epoch  240 Loss:  0.04035891592502594 Test Acc.:  0.748\n",
            "Epoch  250 Loss:  0.1070757731795311 Test Acc.:  0.732\n",
            "Epoch  260 Loss:  0.06245577707886696 Test Acc.:  0.686\n",
            "Epoch  270 Loss:  0.08435805141925812 Test Acc.:  0.718\n",
            "Epoch  280 Loss:  0.04722487926483154 Test Acc.:  0.714\n",
            "Epoch  290 Loss:  0.06513091176748276 Test Acc.:  0.714\n",
            "Epoch  300 Loss:  0.050673872232437134 Test Acc.:  0.706\n",
            "Epoch  310 Loss:  0.05738869309425354 Test Acc.:  0.726\n",
            "Epoch  320 Loss:  0.05891233682632446 Test Acc.:  0.73\n",
            "Epoch  330 Loss:  0.08084598928689957 Test Acc.:  0.726\n",
            "Epoch  340 Loss:  0.05252746492624283 Test Acc.:  0.684\n",
            "Epoch  350 Loss:  0.041383046656847 Test Acc.:  0.704\n",
            "Epoch  360 Loss:  0.11209285259246826 Test Acc.:  0.71\n",
            "Epoch  370 Loss:  0.037695128470659256 Test Acc.:  0.744\n",
            "Epoch  380 Loss:  0.07577959448099136 Test Acc.:  0.72\n",
            "Epoch  390 Loss:  0.051607899367809296 Test Acc.:  0.71\n",
            "Epoch  400 Loss:  0.045833077281713486 Test Acc.:  0.728\n",
            "Epoch  410 Loss:  0.06033756956458092 Test Acc.:  0.718\n",
            "Epoch  420 Loss:  0.0716925784945488 Test Acc.:  0.708\n",
            "Epoch  430 Loss:  0.06118988245725632 Test Acc.:  0.72\n",
            "Epoch  440 Loss:  0.0878349095582962 Test Acc.:  0.7\n",
            "Epoch  450 Loss:  0.06317002326250076 Test Acc.:  0.706\n",
            "Epoch  460 Loss:  0.06569656729698181 Test Acc.:  0.712\n",
            "Epoch  470 Loss:  0.05509461835026741 Test Acc.:  0.72\n",
            "Epoch  480 Loss:  0.08882367610931396 Test Acc.:  0.744\n",
            "Epoch  490 Loss:  0.05244319140911102 Test Acc.:  0.716\n",
            "Maximum accuracy: 0.748\n",
            "Minimum loss: 0.02610740251839161\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e+bTgoJkNBLQu8EiIBioQnYsLv2siquZZurK6z+UNl11VXRtWEFlFXsiEpHQEEQDBB67wklIQkhvZ7fH3cyzGQmZEhCAjPv53nmycy5Zc6dzLz33Peee64YY1BKKeW9/Oq7Akoppc4sDfRKKeXlNNArpZSX00CvlFJeTgO9Ukp5OQ30Sinl5TTQK6WUl9NAr3yeiNwqIokikiMih0VkrohcWN/1Uqq2aKBXPk1EHgVeA/4NNAPaAm8DV5/megJqv3ZK1Q4N9MpniUgkMBF42BjzjTEm1xhTbIz53hjzuIgEi8hrInLI9nhNRIJtyw4RkWQReUJEjgBTRaSRiPwgImkikml73rpeN1IpNNAr33Y+EALMrGT6k8AgIB7oAwwAnnKY3hxoDLQDxmL9nqbaXrcF8oE3z0TFlTodomPdKF8lIrcBrxhjmlcyfTfwR2PMHNvrUcC7xphYERkCLAAaGmMKKlk+HlhijGl0RjZAKQ9pXlH5snQgWkQCjDElbqa3BPY7vN5vKyuX5hjkRSQUeBUYDZQH9wgR8TfGlNZu1ZXynKZulC9bCRQC11Qy/RBWGqZcW1tZuYqHw38DugADjTENgYtt5VLzqipVfdqiVz7LGJMlIhOAt0SkBCsVUwyMAIYCM4CnROQ3rKA+AfjfKVYZgZWXPy4ijYGnz2T9lfKUtuiVTzPGvAI8inWSNQ04CDwCfAv8C0gENgAbgbW2ssq8BjQAjgG/AvPOWMWVOg16MlYppbyctuiVUsrLaaBXSikvp4FeKaW8nAZ6pZTycmdl98ro6GgTGxtb39VQSqlzxpo1a44ZY2LcTTsrA31sbCyJiYn1XQ2llDpniMj+yqZp6kYppbxclYFeRNqIyBIR2SIim0Xkz27mERF5XUR2icgGEennMO0uEdlpe9xV2xuglFLq1DxJ3ZQAfzPGrBWRCGCNiCw0xmxxmOcyoJPtMRCYDAx0uAw8AesS8jUi8p0xJrNWt0IppVSlqgz0xpjDwGHb82wR2Qq0AhwD/dXAx8a6zPZXEYkSkRbAEGChMSYDQEQWYo3sN6NWt0IpL1ZcXExycjIFBW5HQ1Y+JiQkhNatWxMYGOjxMqd1MlZEYoG+wKoKk1phjRFSLtlWVlm5u3WPxbp5A23btj2dainl1ZKTk4mIiCA2NhYRHQjTlxljSE9PJzk5mbi4OI+X8/hkrIiEA18DfzHGnKhGHU/JGPOeMSbBGJMQE+O2h5BSPqmgoIAmTZpokFeICE2aNDntozuPAr2IBGIF+U+MMd+4mSUFaOPwurWtrLJypdRp0CCvylXnu+BJrxsBPgS2GmMmVTLbd8Cdtt43g4AsW25/PjDSdtPkRsBIW1mtKygu5d2fdrN857EzsXqllDpnedKiHwzcAQwTkSTb43IR+YOI/ME2zxxgD7ALeB94CMB2EvafwG+2x8TyE7O1Lcjfj/d+3sNXaw5WPbNSymPHjx/n7bffrtayl19+OcePHz/lPBMmTGDRokXVWn9FsbGxHDtW9429SZMm0bVrV3r16kWfPn149NFHKS4utk9PSkpCRJg3z7pFwbXXXkt8fDwdO3YkMjKS+Ph44uPjWbFixZmpoDHmrHv079/fVMdfPltn+k5cYEpLy6q1vFJnoy1bttTr++/du9f06NHD7bTi4uI6rs2ptWvXzqSlpdXpe06ePNmMGjXKZGZmGmOMKSwsNM8//7zJysqyz/P3v//dXHjhhebOO+90WnbJkiXmiiuuOO33dPedABJNJTHVq66MvahTNBm5RWw7kl3fVVHKa4wbN47du3cTHx/P448/ztKlS7nooosYM2YM3bt3B+Caa66hf//+9OjRg/fee8++bHkLe9++fXTr1o3777+fHj16MHLkSPLz8wG4++67+eqrr+zzP/300/Tr149evXqxbds2ANLS0rj00kvp0aMH9913H+3atauy5T5p0iR69uxJz549ee211wDIzc3liiuuoE+fPvTs2ZPPP//cvo3du3end+/ePPbYY6f1+Tz33HNMnjyZqKgoAIKCghg3bhwNGzYErMb0l19+ybRp01i4cGG9dJM9K8e6qa4+bawPetOhLLq3bFjPtVGq9j37/Wa2HKrdTm/dWzbk6at6VDr9hRdeYNOmTSQlJQGwdOlS1q5dy6ZNm+xd/KZMmULjxo3Jz8/nvPPO4/rrr6dJkyZO69m5cyczZszg/fff56abbuLrr7/m9ttvd3m/6Oho1q5dy9tvv83LL7/MBx98wLPPPsuwYcMYP3488+bN48MPPzzlNq1Zs4apU6eyatUqjDEMHDiQSy65hD179tCyZUtmz54NQFZWFunp6cycOZNt27YhIlWmmhydOHGCnJycU3Z1XLFiBXFxcXTo0IEhQ4Ywe/Zsrr/+eo/fozZ4VYs+rkkYYUH+bE7Jqu+qKOXVBgwY4BTcXn/9dfr06cOgQYM4ePAgO3fudFkmLi6O+Ph4APr378++ffvcrvu6665zmWf58uXcfPPNAIwePZpGjRqdsn7Lly/n2muvJSwsjPDwcK677jqWLVtGr169WLhwIU888QTLli0jMjKSyMhIQkJCuPfee/nmm28IDQ093Y/Dbv78+cTHxxMbG2vPt8+YMcNe95tvvpkZM+r+elGvatH7+Qk9WkWy5oCOsKC806la3nUpLCzM/nzp0qUsWrSIlStXEhoaypAhQ9ymJ4KDg+3P/f397ambyubz9/enpKSkVuvduXNn1q5dy5w5c3jqqacYPnw4EyZMYPXq1fz444989dVXvPnmmyxevNhpuVGjRnH06FESEhL44IMP7OUNGzYkPDycvXv3EhcXx6hRoxg1ahRXXnklRUVFlJaW8vXXXzNr1iyee+45+wVP2dnZRERE1Oq2nYpXtegBhndtyqaUExzMyKvvqijlFSIiIsjOrvy8V1ZWFo0aNSI0NJRt27bx66+/1nodBg8ezBdffAHAggULyMw8dWPuoosu4ttvvyUvL4/c3FxmzpzJRRddxKFDhwgNDeX222/n8ccfZ+3ateTk5JCVlcXll1/Oq6++yvr1613WN3/+fJKSkpyCfLnx48fz4IMP2lM+xhj7ju7HH3+kd+/eHDx4kH379rF//36uv/56Zs6cWdOP5LR4VYseYHi3pjw/dxsr96TTpnH1D8GUUpYmTZowePBgevbsyWWXXcYVV1zhNH306NG88847dOvWjS5dujBo0KBar8PTTz/NLbfcwvTp0zn//PNp3rz5KVvE/fr14+6772bAgAEA3HffffTt25f58+fz+OOP4+fnR2BgIJMnTyY7O5urr76agoICjDFMmlTZ5ULuPfjgg+Tm5jJw4ECCg4MJDw9n8ODB9O3bl7/85S9ce+21TvNff/31TJ48mTvvvPP0P4hqEqtXztklISHBVPfGI3lFJXSfMJ8nRnflwSEdarlmStW9rVu30q1bt/quRr0qLCzE39+fgIAAVq5cyYMPPmg/OeyL3H0nRGSNMSbB3fxe16JvEOhPcIAfmXlF9V0VpVQtOXDgADfddBNlZWUEBQXx/vvv13eVzileF+hFhCZhQaTnaKBXylt06tSJdevW1Xc1zlledzIWoFFYkLbolVLKxisDfeOwINJzNdArpRR4caDP1ECvlFKAFwf6DA30SikFeGugDw0ip7CEwpLS+q6KUue8mgxTDPDaa6+Rl+d7FzCWlJTwj3/8g06dOtmHIX7uueec5vn2228REfvgbQMHDiQ+Pp62bdsSExNjX66y4SI85Z2BPjwIgMzc4irmVEpVxRsCfW0PpeCJp556ikOHDrFx40aSkpJYtmyZ0xj1YI2Dc+GFF9rHv1m1ahVJSUlMnDiR3/3udyQlJZGUlERsbGyN6uKVgb5JmBXoNX2jVM1VHKYY4KWXXuK8886jd+/ePP3004D7IYBff/11Dh06xNChQxk6dKjLuidOnMh5551Hz549GTt2LOUXcO7atYsRI0bQp08f+vXrx+7duwF48cUX7Tf3GDduHABDhgyh/ALLY8eO2YPitGnTGDNmDMOGDWP48OHk5OQwfPhw+xDIs2bNstfj448/pnfv3vTp04c77riD7Oxs4uLi7IH5xIkTTq+rkpeXx/vvv88bb7xBSEgIYA0l8cwzz9jnycnJYfny5Xz44Yd89tlnHq23uqrsRy8iU4ArgVRjTE830x8HbnNYXzcgxhiTISL7gGygFCip7Kqt2tYoVAO98lJzx8GRjbW7zua94LIXKp1ccZjiBQsWsHPnTlavXo0xhjFjxvDzzz+TlpbmMgRwZGQkkyZNYsmSJURHR7us+5FHHmHChAkA3HHHHfzwww9cddVV3HbbbYwbN45rr72WgoICysrKmDt3LrNmzWLVqlWEhoaSkVH1zerWrl3Lhg0baNy4MSUlJcycOZOGDRty7NgxBg0axJgxY9iyZQv/+te/WLFiBdHR0WRkZBAREWEfUviaa67hs88+47rrriMwMNCjj3TXrl20bdv2lMM0zJo1i9GjR9O5c2eaNGnCmjVr6N+/v0frP12etOinAaMrm2iMeckYE2+MiQfGAz8Z59sFDrVNr5MgD9DElrrJ0L70StW6BQsWsGDBAvr27Uu/fv3Ytm0bO3fudDsEcFWWLFnCwIED6dWrF4sXL2bz5s1kZ2eTkpJiHyMmJCSE0NBQFi1axD333GMfRrhx48ZVrv/SSy+1z2eM4R//+Ae9e/dmxIgRpKSkcPToURYvXsyNN95o3xGVz3/fffcxdepUAKZOnco999xz+h+WzdSpU4mPj6dNmzYcPGjd7rQuhy+uskVvjPlZRGI9XN8tQN0PtlyBvUWfU1jPNVGqlp2i5V1XjDGMHz+eBx54wGWauyGAK1NQUMBDDz1EYmIibdq04ZlnnqnW3ZcCAgIoKyuzr9OR43DKn3zyCWlpaaxZs4bAwEBiY2NP+X6DBw9m3759LF26lNLSUnr2dE5olJaW2lvgY8aMYeLEifZpHTt25MCBA/bhiO+55x7uueceevbsSWlpKRkZGSxevJiNGzciIpSWliIivPTSS4jIaX8GVam1HL2IhGK1/L92KDbAAhFZIyJjq1h+rIgkikhiWlpajeoSFRqECGTk6clYpWqq4jDFo0aNYsqUKeTk5ACQkpJCamqq2yGA3S1frjzIRkdHk5OTY7+dYEREBK1bt+bbb78FrAHN8vLyuPTSS5k6dar9xG556iY2NpY1a9YA2NfhTlZWFk2bNiUwMJAlS5awf/9+AIYNG8aXX35Jenq603oB7rzzTm699Va3rXl/f3/7yVLHIA8QGhrKvffeyyOPPGLfztLSUoqKiuz1vOOOO9i/fz/79u3j4MGDxMXFsWzZskrrXxO1eTL2KuCXCmmbC40x/YDLgIdF5OLKFjbGvGeMSTDGJMTExNSoIv5+QlSDQDJytUWvVE05DlP8+OOPM3LkSG699VbOP/98evXqxQ033EB2djYbN25kwIABxMfH8+yzz/LUU08BMHbsWEaPHu1yMjYqKor777+fnj17MmrUKM477zz7tOnTp/P666/Tu3dvLrjgAo4cOcLo0aMZM2YMCQkJxMfH8/LLLwPw2GOPMXnyZPr27XvK+8jedtttJCYm0qtXLz7++GO6du0KQI8ePXjyySe55JJL6NOnD48++qjTMpmZmdxyyy2n/bk999xztGjRgp49e9K3b18uuugi7rrrLlq2bMmMGTPcDl98ptI3Hg1TbEvd/ODuZKzDPDOBL40xn1Yy/RkgxxjzclXvV5NhissNeWkJvVtH8fotfWu0HqXqmw5TXH+++uorZs2axfTp0+u7Kk7qZZhiEYkELgFudygLA/yMMdm25yOBiZWsotZFhASSXaCpG6VU9fzxj39k7ty5zJkzp76rUmOedK+cAQwBokUkGXgaCAQwxrxjm+1aYIExJtdh0WbATNuJhQDgU2PMvNqr+qk1bBDAiYK6v0hCKeUd3njjjfquQq3xpNdNlckpY8w0rG6YjmV7gD7VrVhNNQwJJPVETn29vVK1yhhzRnpjqHNPde4K6JVXxoIV6E9o6kZ5gZCQENLT06v1A1fexRhDenq6/WpbT3ndHabKNWwQwIl8Td2oc1/r1q1JTk6mpt2OlXcICQmhdevWp7WM1wb6iJBA8otLKS4tI9Dfaw9clA8IDAwkLi6uvquhzmFeGwEbhlj7sGw9IauU8nHeG+gbWIMPncjXPL1Syrd5baCPCLEFej0hq5TycV4b6EOD/AHIK9K7TCmlfJvXBvoGtkCfr4FeKeXjvDbQa4teKaUs3hvoA61eN3lF2utGKeXbvDbQ21M3xdqiV0r5Nq8N9Jq6UUopi9cG+gaBGuiVUgq8OND7+QkhgX7ka45eKeXjvDbQA4QGBWiLXinl87w60DcI9Nd+9Eopn+fVgT40yF973SilfF6VgV5EpohIqohsqmT6EBHJEpEk22OCw7TRIrJdRHaJyLjarLgnQoP8NXWjlPJ5nrTopwGjq5hnmTEm3vaYCCAi/sBbwGVAd+AWEelek8qergZBmrpRSqkqA70x5mcgoxrrHgDsMsbsMcYUAZ8BV1djPdUWGhRAXrH2ulFK+bbaytGfLyLrRWSuiPSwlbUCDjrMk2wrc0tExopIoogk1tYt00IC/SgsLquVdSml1LmqNgL9WqCdMaYP8AbwbXVWYox5zxiTYIxJiImJqYVqQXCAP4UlGuiVUr6txoHeGHPCGJNjez4HCBSRaCAFaOMwa2tbWZ0JDvCjsERz9Eop31bjQC8izUVEbM8H2NaZDvwGdBKROBEJAm4Gvqvp+50OK9Bri14p5dsCqppBRGYAQ4BoEUkGngYCAYwx7wA3AA+KSAmQD9xsjDFAiYg8AswH/IEpxpjNZ2QrKhEUoDl6pZSqMtAbY26pYvqbwJuVTJsDzKle1WrOytGXYozBdtChlFI+x6uvjA0O8KPMQEmZqe+qKKVUvfHuQB9obZ7m6ZVSvsy7A32ANSZ9oY53o5TyYV4e6LVFr5RS3h3obambIg30Sikf5t2Bvjx1o4FeKeXDvDzQl6duNEevlPJdXh7otUWvlFJeHeiDylv0enWsUsqHeXWg19SNUkp5e6DXC6aUUsrLA709R68teqWU7/LyQK85eqWU8olAX6BDICilfJhXB/qwYGsU5twiDfRKKd/l1YE+OMCPQH8hp7CkvquilFL1pspALyJTRCRVRDZVMv02EdkgIhtFZIWI9HGYts9WniQiibVZcU+ICOHBAeRqoFdK+TBPWvTTgNGnmL4XuMQY0wv4J/BehelDjTHxxpiE6lWxZsKCA8gp0ECvlPJdntxK8GcRiT3F9BUOL38FWte8WrUnPDiAbG3RK6V8WG3n6O8F5jq8NsACEVkjImNr+b08EhGiqRullG+rskXvKREZihXoL3QovtAYkyIiTYGFIrLNGPNzJcuPBcYCtG3btraqRVhwABm5RbW2PqWUOtfUSoteRHoDHwBXG2PSy8uNMSm2v6nATGBAZeswxrxnjEkwxiTExMTURrUAK3WjOXqllC+rcaAXkbbAN8AdxpgdDuVhIhJR/hwYCbjtuXMmRYQEaPdKpZRPqzJ1IyIzgCFAtIgkA08DgQDGmHeACUAT4G0RASix9bBpBsy0lQUAnxpj5p2BbTil8GAN9Eop3+ZJr5tbqph+H3Cfm/I9QB/XJepWWHAAeUWllJYZ/P2kvqujlFJ1zquvjAUIDbJGsMzX8W6UUj7K6wN9SKAV6HVgM6WUr/L+QB+ggV4p5du8PtDrXaaUUr7O6wO9pm6UUr7OhwK9tuiVUr7J6wP9ydsJaoteKeWbvD7Q21v0eoNwpZSP8oFAX37fWE3dKKV8k/cHelv3ykJt0SulfJT3B3o9GauU8nE+EOjLUzfaoldK+SavD/TBAdqiV0r5Nh8I9NqiV0r5Nq8P9H5+QlCAn3avVEr5LK8P9AAhAX4UaupGKeWjfCPQB/pr90qllM/yKNCLyBQRSRURt/d8FcvrIrJLRDaISD+HaXeJyE7b467aqvjpaBDkT16RBnqllG/ytEU/DRh9iumXAZ1sj7HAZAARaYx1j9mBwADgaRFpVN3KVlej0CAycovq+m2VUuqs4FGgN8b8DGScYpargY+N5VcgSkRaAKOAhcaYDGNMJrCQU+8wzoimEcGkZRfW9dsqpdRZobZy9K2Agw6vk21llZW7EJGxIpIoIolpaWm1VC1LTEQwqRrolVI+6qw5GWuMec8Yk2CMSYiJianVdcdEBJORW0Rxqfa8UUr5ntoK9ClAG4fXrW1llZXXqaYRIQCk52ieXinle2or0H8H3GnrfTMIyDLGHAbmAyNFpJHtJOxIW1mdiokIBtA8vVLKJwV4MpOIzACGANEikozVkyYQwBjzDjAHuBzYBeQB99imZYjIP4HfbKuaaIw51UndMyKyQSAAWfnFdf3WSilV7zwK9MaYW6qYboCHK5k2BZhy+lWrPeXj3RSVal96pZTvOWtOxp5JwYHl943Vk7FKKd/jG4HefpcpDfRKKd/jI4He1qLX8W6UUj7IJwJ9UHmOXlv0Sikf5BOB/mSLXgO9Usr3+Eig1xy9Usp3+USgD/QXRKBQbyeolPJBPhHoRYQgfz9t0SulfJJPBHqw8vQa6JVSvsh3An2gvwZ6pZRP8p1AH+Cn/eiVUj7JZwJ9kKZulFI+ymcCfXCAv14wpZTyST4U6LVFr5TyTb4V6LUfvVLKB/lMoNccvVLKV/lMoA8O0O6VSinf5FGgF5HRIrJdRHaJyDg3018VkSTbY4eIHHeYVuow7bvarPzpCA7U7pVKKd9U5a0ERcQfeAu4FEgGfhOR74wxW8rnMcb81WH+PwJ9HVaRb4yJr70qV0+HmHBmbzjML7uOMbhjdH1XRyml6own94wdAOwyxuwBEJHPgKuBLZXMfwvWzcPPKg8N6cCbi3fy6550DfS+JisZDvzqWh4cAZ1Ggohz+Y4FsOJ1MMa53M8fLp0ILeu93XL2KiuFHfOhOM91WpsBENW27utUX4yBXYugIMt1Wos+EN2pzqriSaBvBRx0eJ0MDHQ3o4i0A+KAxQ7FISKSCJQALxhjvq1k2bHAWIC2bWv/yxAS6E9UaBAZuUW1vu5zSkkR5Ka6lgeGQmhj1/L8TNj3C1Ah6Ik/dBgKgQ3OSDWrJW0HHNvuXGYMzHkcco64X+b2r6HjCOeyVe/AkQ3QrJdzeXIi/PwSXPaic7n4QUQL1x2GL9q1CD67xf20dhfCPbPrtj71Kfk3+OQG99NiusHDbhofZ4gngf503Ax8ZYxxTIa3M8akiEh7YLGIbDTG7K64oDHmPeA9gISEBFNxem1oFBrI8bziqmcsK4O8Y67l/kHQIKp2KlOQBSWFzmXF+bDtByg44Tp/20FWYK1o80xI3eZaHtUG+t7uWv7ZLdaP0YXAg79Asx7OxYufg9/ed78NF/0Nhk9wLkvbDkueg+IC1/n73QndrnS/LneKcq1HRcENITDEucwY+PhqyD7kOr9fINzyOTRuf7KsrAQ+GA5rPrJaoY7rOfArxN8KV7zsvJ45j8Pq96z/UUUjn4MLHvF822rL9nlwaF2FQgMHV8PRTa7zB4ZCt6sgKNy5PCAYBoyF4HDXZU7H4Q3W3weWQYDD/+jXtyDpU+s77knjwBhY8BQc2+k6LbqTdWTl51+zup5pe3+y/t6/GIIiTpav/QhWvgn5x2svnlTBk0CfArRxeN3aVubOzcDDjgXGmBTb3z0ishQrf+8S6OtCI09b9PPGwep3XcvFH66ZDJ1HupaHNPS8Ikc2wrsXgzmNXkB+AdB5tHNZaRHsXFD5Mi37QbPuJ18XZsOepdD1Sug86mR5UR7MewL2LXcN9CmJ0HoAXDnJuXzRM7DiDVj/uXN5wXHr82gc51x+IsUKSGludkodhkGrfs5lhdkwqTsUutnpRbWFR9ZAQNDJssx9VpC/ZJzrziQsBiKau66n06WwZRZsddNHoMMw17Kh/4AW8WAqnNT/caJ1BFBRbrr1XXKXxmjZ13WbT6VJR9e0R3EBfHWP+/WHRFr/54Bg5/LDG6wg405ka+h9k+d1cid1C0S1gxa9ncu7XA5rpsF/+1g7XkedR8IVk5yPiFK3WvVs3N7asZcrLYad8+HwemsbK9Z/xLOujYClL8Da6a51DQiG3/3P+TdSlcJsq5Hg6OgWmP03a5qj/Axo2gNa9Xcu7zjC2rZFz1h1dhQUBoMe9Lw+HvIk0P8GdBKROKwAfzNwa8WZRKQr0AhY6VDWCMgzxhSKSDQwGPhPbVS8OqJCg0jOdPOjqOhwEkR3gYFjncvXTIOZY90uwg1ToOf1nlXk6BYryA990jVd0qq/FQQc5R+HmQ9Axl7XdfW+Ga5+E/wdfjy5x+CVLvDRVVYeulxpkfUlHTAW2l9ystwYWP4q7FzoHOiNgaObYeAfoHmFNMbI56xWWlmFnZWfH5x3n5WDdHRgFUy7Ahb/03Ubtv0AY5c6lx3ZaAX5QQ9Bkw4ny48fhF9eg09vggaNTpZn21Iz3a6C5j1d38Odq9+GwX92LQ8IgaZufvwNGkHf21zL138Omftdy3cugI1fWN8lP4efWnGe+6OCUwkMhYsfd/4/Hz9orevWL10bH6ejpBD+1QzS3bS/SgohZa3rzi19N/z6tutR6YlD0HG463raD4FBD7vmq3OOQOIU2PWjlQIrV5QDCPx+PoQ3PVlenorbvwLyMhxWZKzP9PCGCjt1A1t/sL6/Ff+nGz6DDZ/Dpc9W2IbD1pGyyzbvso4AK6YxARq2gvZujri7j3Eta9UfQqNhzVTXaWFN6yfQG2NKROQRYD7gD0wxxmwWkYlAojGmvDl0M/CZMU5nsLoB74pIGVZXzhcce+vUtcZhgWxM8aBFf/wAdBhuBSxHXa+CLd+6tsQXP2flsT0N9OXphUEPeXao3IJaWUoAACAASURBVCAKbv286vnKhUXD6Besw3d309pd4FwmYqWGtnwLuxa6LtNmgGtZ064w5g3P69R2IDx5xPWzW/pv+OV1K0UTFHay/MhG6+8Ff4KGLU6Wl5VZh/PHdlgnWR11vBSadvO8TsHhrq2t6mgUC7t/dC0/ugkCGsBDK13TDEc3u7YAK1NSALP+CD8+6zotvDnEXXzaVXYSEAyRbSBjj+u05a/C0ufdL9e0O7Q+z7W8/13u32P0v13LS0vgpxfc7yhbxjsHebC+qxVTauV+nAhbvoPcNOfyZj3gd9NdW89ZB2D1+7B9rnN5zhH3J1ABet3o5jsj0PVyz080hzSEx3Y4pwzPMI9y9MaYOcCcCmUTKrx+xs1yK4BeFcvrS6PQIDLzijHGIJWdOCsphOzD7v9pEc1g4AOu5Zu/tQ5ZPXXisHU4WtN86KkMuN96eOqq/8J597qWB4RAq4TaqZO/m69b2wusYPLuJc453ezDVqunYsrFzw9u+bR26lNbGrWz6vvbB86t0t1LrB2Pu1xyxRRZVf60DkryXcsDQpxb+dXVOM76DlfM92+ZZR1hXjrRuVz8rYBXMU1yuvwDYNhTNVtHueETXM8ZncrFf4fED117V7XoYx3FxnR2Lhc/58ZITfj51+k5hto+GXtWiwoNoqikjLyiUsKCA6xWZOY+55lO2FrbUW1clq9Us+7W4fvsv1WYIFbrpmLaI/uQ1UvjbNIgquYtw+qIuwjib7PSU46i2lonn8+FniwtbN0tXf7/wAV/rJ338A8A/4iq56uupt2s3kbvDXGdduk/6+e7cabFXWQ9fIBPBfqIEGtzcwpLrED/1b2wY677mRt3cF/uTufRsG22lddzVJgNB1e5/thTt1qHysrqgXHN2/Vdi5rpPBL+vtc6B1JReLO6r091DBlvyzFXvHYgwDuDvI/xqUDfINA6VCooH8Uy5yg07w0XP+Y8Y1C4+7x0ZTqPsnJuFa2dDt89At+4SaFU7Lutzm3urkE4lzSIgi6jq55PnZN8KtCH2AO97YRgSaGVm+x+9Zl5w763W62hit2xwOqCppRSdcDHAr11oiy/vEVfUuB8ArC2iVgn6pRSqh75zDDF4Niir6NAr5RSZwEN9BWvHFRKKS/jY4He2lynHL226JVSXs7HAr226JVSvsenAr1T98rSEqs3zNk0zK5SSp0BPhXonVr0pbbBmLRFr5Tycj4W6Mu7V5adHHVPc/RKKS/nW4E+wKFFX2K7MYa26JVSXs6nAr2fnxAU4EdBiWOg1xa9Usq7+VSgBwgJ8KPQKXWjLXqllHfzuUBfWmaYtmIfWdm2mz5oi14p5eU8CvQiMlpEtovILhEZ52b63SKSJiJJtsd9DtPuEpGdtoebW8/Urdwiqw/9im22uxNpi14p5eWqHNRMRPyBt4BLgWTgNxH5zs0tAT83xjxSYdnGwNNAAtZA12tsy2bWSu1rIDzAdtGUtuiVUl7Okxb9AGCXMWaPMaYI+AzwdFzfUcBCY0yGLbgvBOp10OtXbrRuWl1aZLstm7bolVJezpNA3wo46PA62VZW0fUiskFEvhKR8tsnebosIjJWRBJFJDEtLc3dLLXi0h7WHX9KCssDvV4Zq5TybrU1Hv33wAxjTKGIPAB8BAw7nRUYY94D3gNISEgwVcx+emb+AXbMAyACWBdcTNiW8tSNtuiVUt7Nk0CfAjje4LS1rczOGJPu8PID4D8Oyw6psOzS061kje1fAaHR0GEoAny/ch89mkfSv3tnaBRX59VRSqm65Emg/w3oJCJxWIH7ZuBWxxlEpIUx5rDt5Rhgq+35fODfItLI9nokML7GtT5dZaUQOxAufwmAl1fP57pWrel/SY86r4pSStW1KgO9MaZERB7BCtr+wBRjzGYRmQgkGmO+A/4kImOAEiADuNu2bIaI/BNrZwEw0RiTcQa249TKSsDP3/6yQZA/+bZulkop5e08ytEbY+YAcyqUTXB4Pp5KWurGmCnAlBrUsebKSsDv5KaGBgWcvG+sUkp5Od+4MrZCoA8J9CdPW/RKKR/hI4G+tEKL3v/kXaaUUsrL+Uigr5CjD/Qnr6ikHiuklFJ1x4cC/ckWfYMgf+vmI0op5QN8M9AH+pOvLXqllI/w/kBfVgYYlxx9rp6MVUr5CB8I9LaWu0OOvk3jUNKyCzmeV1RPlVJKqbrjQ4H+ZIu+b9soANYdPF4fNVJKqTrlk4G+T+soRGBjclY9VUoppeqOTwb6sOAAwoMDyNTUjVLKB/hAoLeddHXI0QOEBweQW6g9b5RS3s8HAr1rix5sPW8KteeNUsr7+WygDw8OIEdb9EopH+CzgT5MUzdKKR/hA4G+PEfvGui1Ra+U8gU+EOiLrb/uTsbqMAhKKR/gA4G+stSNdTJ2+sp9jJj0U93XSyml6ohHgV5ERovIdhHZJSLj3Ex/VES2iMgGEflRRNo5TCsVkSTb47varLxHTpGjz8gt4v9mbWZXao4Oh6CU8lpVBnoR8QfeAi4DugO3iEj3CrOtAxKMMb2Br4D/OEzLN8bE2x5jaqnenqskRx8e5Px6f3peXdVIKaXqlCct+gHALmPMHmNMEfAZcLXjDMaYJcaY8kj5K9C6dqtZA24GNQPIqNCC35eeW1c1UkqpOuVJoG8FHHR4nWwrq8y9wFyH1yEikigiv4rINZUtJCJjbfMlpqWleVAtD1WSugnwE6fXe9I00CulvFOtnowVkduBBOAlh+J2xpgE4FbgNRHp4G5ZY8x7xpgEY0xCTExM7VWqPND7BzoV/3lEZ8Ze3N7+esbqA9qvXinllTwJ9ClAG4fXrW1lTkRkBPAkMMYYU1heboxJsf3dAywF+tagvqfvFFfG/uPybsz/y8VMvec8UrML+W1fRp1WTSml6oIngf43oJOIxIlIEHAz4NR7RkT6Au9iBflUh/JGIhJsex4NDAa21FblPVLJoGblujSPoH+7RgBsStFhi5VS3iegqhmMMSUi8ggwH/AHphhjNovIRCDRGPMdVqomHPhSRAAO2HrYdAPeFZEyrJ3KC8aYOg707lv0jhqGBBIXHcZGDfRKKS9UZaAHMMbMAeZUKJvg8HxEJcutAHrVpII15kGgB+gQE8aBjPw6qJBSStUtn70ytqKIkEByCovPSBU2pWTxwbI9Z2TdSilVFR8I9O4vmKooPDiAnILa63WzfOcx/rtoJwBXvrGcf83eijGm1tavlFKe8oFA7/6CqYoiQqzRLGsrGN/+4SpeXbTDqSyvSG90opSqez4U6Kto0YcEUFxqKCwpq3KVJaVlTJi1iYMZVQ+bUFhyMrhrP32lVH3QQG8TEWxNLx+j/lhOIaVl7lv3a/Zn8vHK/Yz/ZmOVb5+VfzLvn62BXilVD3wg0HuYow+xpqdlF/LfRTtJ+NciZqw+wMGMPJcLqYpKrVZ/cWnVrf+svJOBvrxFb4wh6eBxzdn7sHd/2s2wV5bWdzWUj/Coe+U5zcMcfXiwNUTCZf9dZi9buz+Tp77dBECbxg14bGQXro5vxYl8a53+FcbLcee4Q4u+/GTvd+sP8efPknjr1n5c0buFx5sy7Ze9tIxqwMgezT1eRp2dnp+7DbB2+rZrT1QNlJSW4e8n+llWwgda9B7m6IOdp3dtHsFPO04OrnYwI58/f5bEit3HeN/WVbK0zPDd+kNMX7mP2HGznfLx5TJzT46SWZ662Z2aA8DWwycAK110JKuAjNwijucVceh4vtt1PfP9FsZOX0NZmeFAJcMqb0g+zsrd6afc1roy9OWlTFq4o+oZ69HxvCLKKknRVWSMcft/qYncc/QEfVp2Ia8t2uHxZ3cmlZYZOj45lxfnbbeXZRcUc/F/lrBqz9nxW6hv3hXoPxgB71zo/FjxpjVNqu51U27ybf1o2ziU9FznoYzDgvy59f1VJB08DsCqvRn8acY6/m/WZgBSMvNZvO0ox3LsQ/1w9ESB/fnmlCwmL91tb+UXlZbxzHeb6fn0fAY9/yP9/rmQ+IkLueCFxTz25Qan93Y8X/DivG1c/NISp3WXG/PmL9zy/q+n3NaayC0s8ShlVVRSxt5jubz+485K5ykPnMt2pvHivG01rlt6TiEPf7LW5SYyq/dm2P9njrILiomfuJD/zN/uMq3c4Szrfwrw8oLtdHlqHoUlpbUW4E7kn/61G/+Zt40l21OrnvEMKCkt492fdvOnGet4bdFO1jl8rmv2Z/Ls95trNSX5pxnreG62+4vpj2QVMP3X/aRlW7+3937ebZ+29XA2BzLy+Pecraf1ftkFxcSNn828TYerXedNKVl8v/5QtZc/E7wr0DdsBZFtnB+t+sH5j0Bgg1MuGhJofRRNI4K5rFcL2jQOBU6epI1vE8WoKlImy3Ye4/fTErlrymp7WflOAOD1xbt4cd42Pl65H4DDWQVMW7HP7bq+X3+Ib9Ymk2vr8jlp4clg9O7P1hHFjqPZTss4Bv6U4+6v8h37cSKPfbn+lNtRGWMMPZ6ez8OfrK1y3tRs151QRV8mJtPlqXnc8eFqJi/dTUFxzVq3by/dzeyNh/lqTbK9LLewhJveXck1b/3iMn95gPh01f5K13n7B6v4/bRE8opKeGuJFUjW7M+k01NzmbkuudLlHP20I63SO5idKDi9QF9cWsbbS3dzz9TfTmu5ip79fjPTftl72st9v+EQz8/dxkpbS9lxp/9l4kGm/rLPqQPC6TieV0Ry5skj1fUHj/Pd+kO8v8x9Pf84Yy3/9+0mVu216hLgfzKcle9Ay3vRFZeWcajCb6KktMylJ9z2I9kYA3/9fL3T0bgnvl2XQnpOIY99uZ4/zljHyt3p7EnLOSvOxXlXjv6mj6q9aMuoBkQEB/DPa3oC0KtVJADDujXl5vPa0qV5BEu2pfLNOpeBO+2e/s4K6psPnah0ntAgf3t/+oVbjpyyTo9+sZ4R3Y4w/vKu9iDjaOzHawgK8GP90yOZs/EwDzkE4E9X7efO82Np1jCE4tIyftuXwc87jrFgi611emMfl/UlHTxO1+YRhAT6c6KgmMVbU7mmbys+/+0A/120k0ZhQQD2dRSWlOIvQoC/H7mFJRzLKaRt41BExGmnk5VfTGSDQMrKDJMW7uCavi3p2DSCbyoEyr3HcunWouEpP5NTKf9hOt5rYN6mk5+xYz48M7eIB/9nfV4nCkr4dNUB+rSJ5L+LdnLP4DjO79AEgN22+xTsPJpjX8+TMzdRWmZYtDWV1BOFrN6bwYd3n8f36w+xYMtR2keHcSSrAD8/YfXedHan5RIVGsgL1/VmRLemTgHJ8WS9JyoGq+N5Rby8YDtjL+pA2yahVS6/Jy2HnMISpv6yD4C7B8cxYdYmgvz9mL3xMHdfEEuv1pHM2XiYx0d2paSsjIc+WUv7mHCev66Xy0WFjkF9iy0VmZyZT1Ro0GltF8Co137m6IlC9r1wBYBTJ4iK5zKsThKZAKzYZQX6QD9hVlIKC7Yc5fz21v+vPNBPmLWZGasPsPnZUYTZGm+vLNzBrHUpLHl8CMEB1hH/AVuX6fziUq56cznLnxjGRyv2ER0efMrzaUeyCvjL50lO39+XF2y3jnLG9OCuC2LZlZrD6r0Z3Dqw7Wl/NjXlXYG+BkKDAtj47Cj762v6tmJg+8Y0Cg0iJND6EiTENqpyPefFNrJ/AS/qFM2yncecpr9ze3/utLX4C4qtL+HK8cM4nFXAl4nJzFh9wGkdi7Ye5Yre7o8k8otLyS8u5ZFP1/LDhpOHmv5+wltLdvPWkt28fGMfZqw+wJr9mU7LFpWUMfWXvWTlFxMa5M/sjUfYevgEfdpEMevhwfxpxjqWbk/jL58n2Zc5lHUyeG8/ks2YN5czpEsM79zen6veXM6etFym3zuAizrF2H8wAAu3HOXK3i2YvnI/by7ZxSer9vPVgxfYT4CXcxfojTGs3J1Oj5aRRIZa86/Zn8FfP1/PP6/pySWdrXsXbD6UZd8Jp+UUMnfjYWZvPOz0uRw9UUhMRDALNh9hzqYjbHc4IvrHzI10a9GQrYdPsDM1h8V/u8QpsEz84WT6YO8xK/innijgedv6j+UU8scZ69z+nwCO5xXzh/+t4aEhHQgNOplGPOHB1dgfr9zHzzvS+OCu85w+V4A5G4/wv18PMHvDYZY9MYzw4ACKSso4mJlHh5hwl3WNefMXexdigILiUvsRJlgnics/h//9esBevmpvBs+O6eFS3wzbzrWktIxtR6zPM+V4Pj1bRVJcWsaspEO0jAqha/OG3PjOCv57c1962hpRFR09YR1hTV66m99fGEty5smd2v70PKat2EfSweP835XdufGdFfZpy3Za59Jyi0r582fW9zXPto3lLfYvEq17J+1Oy2HK8r2MiW/Jit3pHMoqYN6mIwzp0pR9x3LZlXpyh56cmc/BjDx7A66guA+9W0fSqVkEM1YfILZJGE/O3MiAuMaM6dMSsM67RYcHA9h/cz9sOMT5HZow8tWfARjaNYYWkQ04llPIhFmb6Na8Idf0bWXPIpwJcjYcVlSUkJBgEhMT67saLowxXPnGcm4e0JZdR7P5aOV+WkaG2ANg47Ag1jw1guzCEt5espuxF7en3z8X2pdvGRnCz38fSscn5xIW5E9QgB83ndeG8Zd1A6ybn4z/ZiOXdI7h1z3p9tZIz1YN2ZTifJTQrGGw/YdRUXhwgNOP2Z3r+rXim7Xuj04euKQ97/5U+dg8ESEBlJQa8m2plku7N2OhrZX/lxGduKpPS4a/8hMAzRuG0DgsCD8/XLahokcv7cyfhncCrJbuyj3p/OF/awBoFdWA5U8MRUQY/80GZqw+SPvoMBY/NoS1BzK568PVVV6n8Nat/Vh3IJMPlledsogIDuDKPi2YsfpglfMCxEWH2XcA5U71P3KUNOFSft55jFZRDXj3p938YUgH5m48zKaUE0y/dwAdn7Ru2Dbx6h4s3pbK0u1WYLvr/HZ8tNI57bRy/DDGfryGjSlZfD52EHExYUQEB7Jo61Eu6RJD72cWOM3v7rtVmU/uG8jcTYeddgChQf60axLGpJv62HusTbiyO7cObMurC3fY04zldR3aJYap9wzg01UH+HptMncMasdVfVoiQPt/nBw3cVjXpqTnFLI+2RpRdmBcY1bttVr40eHBTufBqvLI0I68uWQXAD1aNnQ54u7XNoqSMsOGZM9Gr/36wfO5fvJKp7Irerdg9gb3ef3o8CCO5ZxMAz13bU9uG9iOf8/Zynu2zyciJICV44dz9ESB2x20J0Rkje0mT67TNNBXT0lpGblFpSzdnsq6A8cZe3F7okIDCa1w0/Eft1oBsFPTCBqFBRIREsjutBwiGwTSMCSQoICTh/FzNx7mwU/WMqxrU168vje703K4+T33J1b/NLyT/URnh5gwZj1yIT2fng/ADf1b89WaZC7pHOPUcwjg3Tv688D0NU5lnvxwFvz1YhZuOcrwbk1Zf/A4T3ztfLHYjf1bs2R7GsdyCmkQ6G/fCTw4pAOTl7qmnZqEBdlPdj95eTd+2HCI9clZJLRrxI0JrV3WD/DR7wdwXmwjRrzyk33n+v6dCdz/sfVd6dg03KlF5rgza9cklIzcIkIC/cnKK7ZfCwFw9wWxfLJqP8Wlht6tI11+8Nf1bUWzyBAGd4jm9g9XARAc4EdhSRmNw4LIyi92e3Hd+e2bMLRrDHuP5dG9RYTT+RpHAX5CSZkhyN+PotIyj3cQ5Xq1isTPT1h/8LjT/7xFZAiHHY7ChnSJYcXudIoqXP3dKDSQTA9TSFGhgRx3M+/vEtrwua3VHBEcYN/pDu0Sw/rkLHvLP9BfaB4ZwkGHkWIv6hTNU1d0Z9RrP7us1zHVWR19Wkfadxbl2jYOtR8Z9W0bxboD1gnlfm2jGNS+CXlFpaxPPm4vr4q7zyQmIth+DqiiiJAALu4Uw+yNzjuGTk3DycwrYunjQ116AXriVIFeUzfVFODvR2QDP66Ob8XV8ZXfQnd4t2YuZZXtsYNtJ4SjQgOJiQimSdjJPOe2f44mJNCfzYeySM7MZ1BcE3an5tCpWTiX92pBeHAAk27qQ+dmEXRsGs4fLulAx6bhDH15qVNLc0S3Zvx9dBc6N40gu7CYCzpE0zAkkGvf/oVtR7JJaNeIQH8/pv3+PLo8Nc++XPvoMB4e2hGA2CZhrNydTlRoENNW7OODOxMY0b0ZV76xjGM5hZSUlfHAxe2576L2rD1wMmW06h/D2Xcsl5Tj+QyIa8yFLy7h6viW3H9xe/q0ieLRL5JI3J9JYoU005+Hd2Lain1OJ7mv79ear9cm24M8wLjRXXn0iyROFJQw/d4BXNAhmrX7M/njsE70ah3JqNd+JrughCdGdyUhthE3vmO1yp4Z04NPbCdkr+3byinQt4pqwH9u6G3Pq3dtHsG2I9mM6NaM2RsPc/vAtlzfvzWRDQLJLy7l/OcXA9aRzU0JbWgZdbITwPNzt5FXVMpTV3TjX7NP9gYpse0kync+FYN847AgcgpL7AG6a/MIXrmpDy0iG7D9SDatGzWgTeNQHpieyPzNVsPiw7sSuPcj58ZS+ZFAuSWPDaFpRDDBAX5M/WUfC7ccpVuLCD5auZ/4NlGknihwStcBboM8wOeJBwkK8KN7i4ZOPZxuG9iOFlGpfLrKOgooLjUcPu68zmU7jzmlYjo1DefPIzrxyKfriIsOI75NFHuP5fL7wXG0aRzKS/O3ExESwPBuTfltbwYfrdxP1+YRhAcHMLpnc2IigmkQ6E/rRqFsPpTF+q+ce7C9e0d/+9HHW7f244IXrP/ZjLGD7Ll6sNKT5Tufz8YOIi27kC8SDzqlY6/s3YKHhnTk/o8TiY4IZr1t2x+4uD3fbzjMhCu7M/GHLfbyLs0iaNcklAVuzs/tTM3hPzf0rlaQr4q26M8iJaVl/PfHnfx+cJz9xOeqPem0iGzg0Yk2d7YePsGU5Xt58opuZBeUVJoHzC8qpbisjJAAfwL9rQtPlmxLJTOviJZRDRhkO7lVUUFxqf0cxs6j2Ww/ms2VvVvap6dmFzDguR+d0jLlNiQfp12TMCIbnMzVf7BsD/+avZXuLRqy5fAJfpfQhhdv6E1yZh6vLNjBTFse/pdxw5i/6QiHs/J5f9leFj16CR2bhrM/PZfMvGLi20S51PXRz5P4Zl0K/7t3IBd2iubeab+x/Wg2y58YRuy42QAsevRi/j1nG4u3pbLZds4mzOGHl5VXjMFQUmZYtOUoNyW0wc928reszNjTD+UnFB3tPJpNcmY+F3eO4eu1yTzz3Wb6t2tEy8gG7EvP5dLuzfh+w2HKygyPjerCwYw8urWIoGPTCIwxLN91jEc+Xccdg9rZOw04Sjmez+Nfrmd4t2bce2Ec93+cyMItR/nfvQPJyi/m4U+tk89/HdGZ9NxCnrmqh73u5RZtOcp9HydyZe8WTLopnjFvLudYThF+Aqm2FuqXfzifRqGBjJhkBcHyHVf/do0Y2iWGlxfsYEBcYw5m5PHj3y5h25Fsrnt7hdP7LPv7UC76zxKnst8PjqN360gGtW9Cs4bBvPvzHi7uFEP3lpWfoN97LJcxby5nxv2D3Ob+jTHsTM2hc7MIrn5zOa0aNeDt2/ozb9MRwoL9uahTDK//uBN/P7E3ZMqVlRmen7uVy3q1oF9b6/zcF4kH+ftXG7jr/HbcdUEscdFhiAgFxaUUlZbxyvztRIQE8reRne3neErLDPM3H+GhT9Zyz+BYnr6qB3AyVVtOBPb8+/JqX/R1qhY9xpgqH8BoYDuwCxjnZnow8Llt+iog1mHaeFv5dmCUJ+/Xv39/o7zHsewCU1ZW5vH8+4/lmuyCYvPT9lRzIr/IadqcDYfM07M2OZXlFZZ4tN4jWfnm33O2mIJi1/n/MD3RtHviB1NWVmYKiktMek6hx/V19MVvB8ymlOPVWrYqZWVlZs6GQya/yLPtLSopNRkO27Fi1zFzw+RfTFp2QaXLFBaXmv/7dqNJzsyzv2dJaZk5fDzfbD9ywmnZX3cfM6v3phtjjNmckmXSsgtMQXGJ+eK3A6a4pNRpvY9/mWRenr/NjHljmfl01X5TUlpm2j3xg2n3xA9m59Fs88qC7aaowjK1Lbew2O3//nQUFpea1xbuqNb3Y96mwy7/u92p2ea3venmQHquOXoiv0Z1w7rjn9uYWmWLXkT8gR3ApUAy1j1kbzEOtwQUkYeA3saYP4jIzcC1xpjfiUh3YAYwAGgJLAI6G2NOmXTz1Ra9qj8lpWUUlxoaBJ36wjpVe6av3Ee3Fg1JiG1c31XxCqdq0XtywdQAYJcxZo8xpgj4DLi6wjxXA+Wd2L8Chot1/HE18JkxptAYsxerZT+gOhuh1JkU4O+nQb6O3XF+rAb5OuJJoG8FOPYxS7aVuZ3HGFMCZAFNPFxWKaXUGXTWDIEgImNFJFFEEtPS0qpeQCmllEc8CfQpQBuH161tZW7nEZEAIBJI93BZAIwx7xljEowxCTExMZ7VXimlVJU8CfS/AZ1EJE5EgoCbge8qzPMdcJft+Q3AYttZ4O+Am0UkWETigE7AapRSStWZKnvmG2NKROQRYD7gD0wxxmwWkYlY3Xm+Az4EpovILiADa2eAbb4vgC1ACfBwVT1ulFJK1S69YEoppbxATbtXKqWUOodpoFdKKS93VqZuRCQNqPy2P6cWDRyrci7votvsG3SbfUN1t7mdMcZtl8WzMtDXhIgkVpan8la6zb5Bt9k3nIlt1tSNUkp5OQ30Sinl5bwx0L9X3xWoB7rNvkG32TfU+jZ7XY5eKaWUM29s0SullHKggV4ppbyc1wR6ERktIttFZJeIjKvv+tQWEZkiIqkissmhrLGILBSRnba/jWzlIiKv2z6DDSLSr/5qXn0i0kZElojIFhHZLCJ/tpV77XaLSIiIrBaR9bZtftZWHiciq2zb9rltYEFsAwV+bitfJSKx9Vn/mhARfxFZJyI/MSQP8AAAAwFJREFU2F579TaLyD4R2SgiSSKSaCs7o99trwj0ttsdvgVcBnQHbrHdxtAbTMO6Z6+jccCPxphOwI+212BtfyfbYywwuY7qWNtKgL8ZY7oDg4CHbf9Pb97uQmCYMaYPEA+MFpFBwIvAq8aYjkAmcK9t/nuBTFv5q7b5zlV/BrY6vPaFbR5qjIl36C9/Zr/bld1M9lx6AOcD8x1ejwfG13e9anH7YoFNDq+3Ay1sz1sA223P38W6n6/LfOfyA5iFdc9in9huIBRYCwzEukIywFZu/55jjSZ7vu15gG0+qe+6V2NbW9sC2zDgB0B8YJv3AdEVys7od9srWvT43i0LmxljDtueHwGa2Z573edgOzzvC6zCy7fblsJIAlKBhcBu4Lixbs8JzttV2e07zzWvAX8Hymyvm+D922yABSKyRkTG2srO6He7yvHo1dnNGGNExCv7yIpIOPA18BdjzAnrfvMWb9xuY92rIV5EooCZQNd6rtIZJSJXAqnGmDUiMqS+61OHLjTGpIhIU2ChiGxznHgmvtve0qL3+JaFXuKoiLQAsP1NtZV7zecgIoFYQf4TY8w3tmKv324AY8xxYAlW2iLKdntOcN6uym7feS4ZDIwRkX3AZ1jpm//i3duMMSbF9jcVa4c+gDP83faWQO/J7Q69ieOtG+/CymGXl99pO1M/CMhyOBw8Z4jVdP8Q2GqMmeQwyWu3W0RibC15RKQB1jmJrVgB/wbbbBW32d3tO88ZxpjxxpjWxphYrN/sYmPMbXjxNotImIhElD8HRgKbONPf7fo+MVGLJzguB3Zg5TWfrO/61OJ2zQAOA8VY+bl7sfKSPwI7gUVAY9u8gtX7aDewEUio7/pXc5svxMpjbgCSbI/LvXm7gd7AOts2bwIm2MrbY91neRfwJRBsKw+xvd5lm96+vrehhts/BPjB27fZtm3rbY/N5bHqTH+3dQgEpZTyct6SulFKKVUJDfRKKeXlNNArpZSX00CvlFJeTgO9Ukp5OQ30Sinl5TTQK6WUl/t/axUPPn9UWhkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# GAT\n",
        "def main():\n",
        "    for args in [\n",
        "        {'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
        "         'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 500, \n",
        "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, \n",
        "         'weight_decay': 5e-3, 'lr': 0.01},\n",
        "    ]:\n",
        "        args = objectview(args)\n",
        "        for model in ['GAT']:\n",
        "            args.model_type = model\n",
        "\n",
        "            # Match the dimension.\n",
        "            if model == 'GAT':\n",
        "              args.heads = 2\n",
        "            else:\n",
        "              args.heads = 1\n",
        "\n",
        "            if args.dataset == 'cora':\n",
        "                dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
        "            else:\n",
        "                raise NotImplementedError(\"Unknown dataset\") \n",
        "            test_accs, losses = train(dataset, args) \n",
        "\n",
        "            print(\"Maximum accuracy: {0}\".format(max(test_accs)))\n",
        "            print(\"Minimum loss: {0}\".format(min(losses)))\n",
        "\n",
        "            plt.title(dataset.name)\n",
        "            plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n",
        "            plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHELqjARZ1W5"
      },
      "source": [
        "## Question 1.1: What is the maximum accuracy you could get on test set for GraphSage?\n",
        "\n",
        "Maximum accuracy:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlCtBEBLMBkR"
      },
      "source": [
        "## Question 1.2: What is the maximum accuracy you could get on test set for GAT?\n",
        "\n",
        "Maximum accuracy:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7JXsMTBgeOI"
      },
      "source": [
        "# Submission\n",
        "\n",
        "In order to get credit, you need to submit the `ipynb` file of Colab 3 to LMS.\n",
        "To get this file, click `File` and `Download .ipynb`. Please make sure that your output of each cell is available in your `ipynb` file."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}